{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "log_interval = 10\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "epochs = 9\n",
    "lr = 0.1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss for epoch:1: 0.1445738951206954\n",
      "Accuracy: 95.62\n",
      "Avg Test loss: 0.14839309006929396\n",
      "Train loss for epoch:2: 0.14359392654170583\n",
      "Accuracy: 95.80\n",
      "Avg Test loss: 0.1483381763100624\n",
      "Train loss for epoch:3: 0.1396406494519874\n",
      "Accuracy: 96.14\n",
      "Avg Test loss: 0.14087455049157144\n",
      "Train loss for epoch:4: 0.1361090848738673\n",
      "Accuracy: 95.34\n",
      "Avg Test loss: 0.16009698957204818\n",
      "Train loss for epoch:5: 0.13229596595972903\n",
      "Accuracy: 96.55\n",
      "Avg Test loss: 0.12261295318603516\n",
      "Train loss for epoch:6: 0.13283343903515846\n",
      "Accuracy: 96.20\n",
      "Avg Test loss: 0.12719205915927886\n",
      "Train loss for epoch:7: 0.1262872539307259\n",
      "Accuracy: 96.15\n",
      "Avg Test loss: 0.12773193046450615\n",
      "Train loss for epoch:8: 0.12612260686857169\n",
      "Accuracy: 95.81\n",
      "Avg Test loss: 0.14521103650331496\n",
      "Train loss for epoch:9: 0.1270634271919346\n",
      "Accuracy: 96.37\n",
      "Avg Test loss: 0.1246478572487831\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    batch_count = 0\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        total_loss += loss.data[0]\n",
    "        batch_count +=1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if batch_idx % log_interval == 0:\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            #    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            #    100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    avg_loss = total_loss/batch_count\n",
    "    print('Train loss for epoch:{0}: {1}'.format(epoch, avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test():\n",
    "    # TODO: Test the model on the test-set and report the loss and accuracy.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Loop through the test loader in batches of 1000\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        #images, labels = Variable(images), Variable(labels)\n",
    "        output = model(Variable(images))\n",
    "        \n",
    "        # Calculate NLL loss\n",
    "        loss = F.nll_loss(output, Variable(labels))\n",
    "\n",
    "        # Add it to the total loss\n",
    "        total_loss += loss.data[0]\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Calculate class predictions\n",
    "        _, prediction = torch.max(output.data, 1)\n",
    "        batch_corr = (prediction == labels).sum()\n",
    "        #print('Batch correct: {0}, Batch size: {1}'.format(batch_corr, labels.size(0)))\n",
    "        correct += batch_corr\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    print('Accuracy: {:.2f}'.format(acc))\n",
    "    avg_loss = total_loss/batch_count\n",
    "    print('Avg Test loss: {0}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "    \n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss.append(train(epoch))\n",
    "    test_loss.append(test())\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13498d3278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCM455wAvCM455xJeEJxzzgHwPyxd9nO653vfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x126def0828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, epochs+1), train_loss, '-o', label = \"Training loss\" )\n",
    "plt.plot(range(1, epochs+1), test_loss, '-*', label = \"Test loss\")\n",
    "plt.legend()\n",
    "plt.title('Plot of train and test loss on every epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "Changes to code:\n",
    "- The test() had the code enhancements.\n",
    "- The code loops through the test loader in batches of size 1000.\n",
    "- The output is calculated using net model which returns a softmax output of probabilities.\n",
    "- Negative log likelihood loss is found based on output and labels.\n",
    "- Total loss is calculated to find average later.\n",
    "- The index of max value per row is found to assign the predicted class.\n",
    "- Correct outputs are accumulated to find accuracy later.\n",
    "- All the test and train losses are appended in a list to plot the above figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "epochs = 9\n",
    "batch_sizes = [64, 32, 128]\n",
    "learning_rates = [ 0.1, 0.01, 0.05, 0.5]\n",
    "momentum = [0, 0.9 ]\n",
    "weight_decay = [0, 0.1]\n",
    "dampening = [0]\n",
    "nesterov = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return test(train_loader)\n",
    "\n",
    "\n",
    "def test(test_loader):\n",
    "    # TODO: Test the model on the test-set and report the loss and accuracy.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        #images, labels = Variable(images), Variable(labels)\n",
    "        output = model(Variable(images))\n",
    "        \n",
    "        loss = F.nll_loss(output, Variable(labels))\n",
    "        #print('Loss: {0}'.format(loss.data[0]))\n",
    "        total_loss += loss.data[0]\n",
    "        batch_count += 1\n",
    "        _, prediction = torch.max(output.data, 1)\n",
    "        batch_corr = (prediction == labels).sum()\n",
    "        #print('Batch correct: {0}, Batch size: {1}'.format(batch_corr, labels.size(0)))\n",
    "        correct += batch_corr\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    #print('Accuracy: {:.2f}'.format(acc))\n",
    "    error = 100-acc\n",
    "    avg_loss = total_loss/batch_count\n",
    "    #print('Avg Test loss for epoch {0}: {1}'.format(epoch, avg_loss))\n",
    "    return avg_loss, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final epoch: 9, train loss: 0.14741937276611386, train error: 4.239999999999995, test error: 4.010000000000005 for parameters: batch_size = 64, lr = 0.1, momentum = 0, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.6886434673881734, train error: 21.441666666666663, test error: 20.510000000000005 for parameters: batch_size = 64, lr = 0.1, momentum = 0, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 2.3119377284161824, train error: 90.07, test error: 89.68 for parameters: batch_size = 64, lr = 0.1, momentum = 0.9, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 1.3342442452780474, train error: 44.891666666666666, test error: 45.37 for parameters: batch_size = 64, lr = 0.1, momentum = 0.9, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.22110817723198614, train error: 6.541666666666671, test error: 5.909999999999997 for parameters: batch_size = 64, lr = 0.01, momentum = 0, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.5466606050157852, train error: 14.784999999999997, test error: 13.980000000000004 for parameters: batch_size = 64, lr = 0.01, momentum = 0, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.15928342216598518, train error: 4.5716666666666725, test error: 4.459999999999994 for parameters: batch_size = 64, lr = 0.01, momentum = 0.9, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.5438270235557292, train error: 15.376666666666665, test error: 14.200000000000003 for parameters: batch_size = 64, lr = 0.01, momentum = 0.9, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.15149709151219776, train error: 4.469999999999999, test error: 4.299999999999997 for parameters: batch_size = 64, lr = 0.05, momentum = 0, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.6037823413607917, train error: 18.35666666666667, test error: 17.58 for parameters: batch_size = 64, lr = 0.05, momentum = 0, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.7476275149566024, train error: 19.635000000000005, test error: 18.120000000000005 for parameters: batch_size = 64, lr = 0.05, momentum = 0.9, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.9188115391522836, train error: 30.316666666666663, test error: 29.680000000000007 for parameters: batch_size = 64, lr = 0.05, momentum = 0.9, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.18722895141157012, train error: 5.87833333333333, test error: 5.400000000000006 for parameters: batch_size = 32, lr = 0.1, momentum = 0, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.7277204879442851, train error: 22.53333333333333, test error: 21.849999999999994 for parameters: batch_size = 32, lr = 0.1, momentum = 0, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 2.310955144627889, train error: 89.78166666666667, test error: 89.9 for parameters: batch_size = 32, lr = 0.1, momentum = 0.9, decay = 0, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 2.303476532872518, train error: 89.78166666666667, test error: 89.9 for parameters: batch_size = 32, lr = 0.1, momentum = 0.9, decay = 0.1, dampening = 0, nest = False\n",
      "Final epoch: 9, train loss: 0.1714878290300568, train error: 5.034999999999997, test error: 4.489999999999995 for parameters: batch_size = 32, lr = 0.01, momentum = 0, decay = 0, dampening = 0, nest = False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-09311e581bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-cc8020c1c6e6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-cc8020c1c6e6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#images, labels = Variable(images), Variable(labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f55881f75f40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for m in momentum:\n",
    "            for decay in weight_decay:\n",
    "                for damp in dampening:\n",
    "                    for is_nest in nesterov:\n",
    "                        seed = 1\n",
    "                        log_interval = 10\n",
    "                        test_batch_size = 1000\n",
    "                        torch.manual_seed(seed)\n",
    "\n",
    "                        train_loader = torch.utils.data.DataLoader(\n",
    "                            datasets.MNIST('../data', train=True, download=True,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                           ])),\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "                        test_loader = torch.utils.data.DataLoader(\n",
    "                            datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                           ])),\n",
    "                            batch_size=test_batch_size, shuffle=True)\n",
    "                        \n",
    "                        # Initialize Model and optimizer\n",
    "                        model = Net()\n",
    "                        optimizer = optim.SGD(model.parameters(), lr = lr, momentum = m, \n",
    "                                              weight_decay = decay, dampening = damp, nesterov = is_nest)\n",
    "                        \n",
    "\n",
    "                        for epoch in range(1, epochs + 1):\n",
    "                            train_loss, train_error = train(train_loader)\n",
    "                            if train_loss < 0.13:\n",
    "                                break\n",
    "                            #test_loss.append(test())\n",
    "                        test_loss, test_error = test(test_loader)\n",
    "                        print('Final epoch: {0}, train loss: {9}, train error: {1}, test error: {2} for parameters: batch_size = {3}, lr = {4}, momentum = {5}, decay = {6}, dampening = {7}, nest = {8}'.format(epoch,\n",
    "                        train_error, test_error, batch_size, lr, m, decay, damp, is_nest, train_loss))\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report for 3.b\n",
    "\n",
    "- Various parameters like batch_size, learning rate, momentum, weight decay were changed to find best results. \n",
    "- Dampening and Nesterov momentum were avoided as Nesterow required momentum>0 and dampening =0. This was difficult to manage in the for loop.\n",
    "- The best parameters found are: batch_size = 64, learning rate = 0.1, momentum = 0, weight decay = 0, dampening = 0, nesterov = False.\n",
    "- The best parameters are decided based on training loss, training error and testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
